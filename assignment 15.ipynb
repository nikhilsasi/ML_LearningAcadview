{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =load_digits()\n",
    "x=df.data\n",
    "y=df.target\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"GAUSSIAN KERNEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.44      0.61        43\n",
      "          1       1.00      0.73      0.84        37\n",
      "          2       1.00      0.79      0.88        38\n",
      "          3       1.00      0.74      0.85        46\n",
      "          4       1.00      0.27      0.43        55\n",
      "          5       1.00      0.02      0.03        59\n",
      "          6       1.00      0.71      0.83        45\n",
      "          7       1.00      0.66      0.79        41\n",
      "          8       0.15      1.00      0.26        38\n",
      "          9       1.00      0.25      0.40        48\n",
      "\n",
      "avg / total       0.93      0.52      0.57       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[19  0  0  0  0  0  0  0 24  0]\n",
      " [ 0 27  0  0  0  0  0  0 10  0]\n",
      " [ 0  0 30  0  0  0  0  0  8  0]\n",
      " [ 0  0  0 34  0  0  0  0 12  0]\n",
      " [ 0  0  0  0 15  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  1  0  0 58  0]\n",
      " [ 0  0  0  0  0  0 32  0 13  0]\n",
      " [ 0  0  0  0  0  0  0 27 14  0]\n",
      " [ 0  0  0  0  0  0  0  0 38  0]\n",
      " [ 0  0  0  0  0  0  0  0 36 12]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\",confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is : 0.5222222222222223\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = model.score(x_test, y_test)\n",
    "print(\"The accuracy score is : {}\".format(accuracy_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5222222222222223"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"POLY KERNEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=SVC(kernel='poly',degree=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=6, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       0.95      0.97      0.96        37\n",
      "          2       1.00      1.00      1.00        38\n",
      "          3       0.98      0.96      0.97        46\n",
      "          4       1.00      1.00      1.00        55\n",
      "          5       0.98      1.00      0.99        59\n",
      "          6       1.00      1.00      1.00        45\n",
      "          7       0.98      0.98      0.98        41\n",
      "          8       0.95      0.92      0.93        38\n",
      "          9       0.96      0.96      0.96        48\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 38  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 55  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 59  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  1]\n",
      " [ 0  2  0  0  0  0  0  0 35  1]\n",
      " [ 0  0  0  1  0  0  0  1  0 46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\",confusion_matrix(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is : 0.98\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = model2.score(x_test, y_test)\n",
    "print(\"The accuracy score is : {}\".format(accuracy_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"LINEAR KERNEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3=model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       0.97      1.00      0.99        37\n",
      "          2       0.97      1.00      0.99        38\n",
      "          3       0.98      0.93      0.96        46\n",
      "          4       1.00      0.98      0.99        55\n",
      "          5       0.97      1.00      0.98        59\n",
      "          6       1.00      1.00      1.00        45\n",
      "          7       0.98      0.98      0.98        41\n",
      "          8       1.00      0.97      0.99        38\n",
      "          9       0.96      0.96      0.96        48\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Classification Report\", classification_report(y_test, pred3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 38  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 43  0  1  0  0  0  1]\n",
      " [ 0  1  0  0 54  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 59  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 37  0]\n",
      " [ 0  0  0  1  0  0  0  1  0 46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\",confusion_matrix(y_test, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is : 0.9822222222222222\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = model3.score(x_test, y_test)\n",
    "print(\"The accuracy score is : {}\".format(accuracy_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"SIGMOID KERNEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4=model4.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        43\n",
      "          1       0.08      1.00      0.15        37\n",
      "          2       0.00      0.00      0.00        38\n",
      "          3       0.00      0.00      0.00        46\n",
      "          4       0.00      0.00      0.00        55\n",
      "          5       0.00      0.00      0.00        59\n",
      "          6       0.00      0.00      0.00        45\n",
      "          7       0.00      0.00      0.00        41\n",
      "          8       0.00      0.00      0.00        38\n",
      "          9       0.00      0.00      0.00        48\n",
      "\n",
      "avg / total       0.01      0.08      0.01       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"Classification Report\", classification_report(y_test, pred4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[ 0 43  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0 55  0  0  0  0  0  0  0  0]\n",
      " [ 0 59  0  0  0  0  0  0  0  0]\n",
      " [ 0 45  0  0  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  0  0  0  0]\n",
      " [ 0 48  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\",confusion_matrix(y_test, pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is : 0.08222222222222222\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = model4.score(x_test, y_test)\n",
    "print(\"The accuracy score is : {}\".format(accuracy_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08222222222222222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
